{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py:151: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert ((x is not None) != (paths_probs is not None and distribs is not None),\n"
     ]
    }
   ],
   "source": [
    "import newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arguments = namedtuple('Arguments', ['max_depth', 'cuda', 'input_dim', 'output_dim', 'lmbda', 'lr', 'momentum',\n",
    "                                     'log_interval', 'epochs', 'l1_const', 'mode'\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments(max_depth=3, cuda=True, input_dim=20, output_dim=3, lmbda=0.1, lr=0.1, momentum=0.1,\n",
    "                 log_interval=100, epochs=20, l1_const=0.01, mode='argmax'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('max_depth', 3),\n",
       "             ('cuda', True),\n",
       "             ('input_dim', 20),\n",
       "             ('output_dim', 3),\n",
       "             ('lmbda', 0.1),\n",
       "             ('lr', 0.1),\n",
       "             ('momentum', 0.1),\n",
       "             ('log_interval', 100),\n",
       "             ('epochs', 20)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py:151: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert ((x is not None) != (paths_probs is not None and distribs is not None),\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_classes=3, n_informative=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExampleData(Dataset):\n",
    "        def __init__(self, x, y):\n",
    "            super(ExampleData, self).__init__()\n",
    "\n",
    "            self.len = x.shape[0]\n",
    "            self.x_data = torch.from_numpy(x).type(torch.FloatTensor).cuda()\n",
    "            self.y_data = torch.from_numpy(y).type(torch.LongTensor).view(-1).cuda()\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.x_data[index], self.y_data[index]\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=ExampleData(X_train, y_train),\n",
    "                          batch_size=64,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=ExampleData(X_test, y_test),\n",
    "                         batch_size=64,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments(max_depth=4, cuda=True, input_dim=20, output_dim=3, lmbda=0.1, lr=0.001, momentum=0,\n",
    "                 log_interval=300, epochs=200, l1_const=-1, mode='mean'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = newmodel.SoftDecisionTree(args)\n",
    "tree.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "batch 0\t-\tLoss: 14.3861\t-\tAccuracy: 0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 300\t-\tLoss: 1.3230\t-\tAccuracy: 0.375\n",
      "batch 600\t-\tLoss: 1.2527\t-\tAccuracy: 0.391\n",
      "batch 900\t-\tLoss: 1.2359\t-\tAccuracy: 0.328\n",
      "batch 1200\t-\tLoss: 1.2249\t-\tAccuracy: 0.219\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 1\n",
      "batch 0\t-\tLoss: 1.2190\t-\tAccuracy: 0.359\n",
      "batch 300\t-\tLoss: 1.2156\t-\tAccuracy: 0.297\n",
      "batch 600\t-\tLoss: 1.2145\t-\tAccuracy: 0.328\n",
      "batch 900\t-\tLoss: 1.2129\t-\tAccuracy: 0.391\n",
      "batch 1200\t-\tLoss: 1.2148\t-\tAccuracy: 0.281\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 2\n",
      "batch 0\t-\tLoss: 1.2149\t-\tAccuracy: 0.297\n",
      "batch 300\t-\tLoss: 1.2136\t-\tAccuracy: 0.344\n",
      "batch 600\t-\tLoss: 1.2128\t-\tAccuracy: 0.359\n",
      "batch 900\t-\tLoss: 1.2116\t-\tAccuracy: 0.359\n",
      "batch 1200\t-\tLoss: 1.2135\t-\tAccuracy: 0.312\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 3\n",
      "batch 0\t-\tLoss: 1.2111\t-\tAccuracy: 0.406\n",
      "batch 300\t-\tLoss: 1.2132\t-\tAccuracy: 0.391\n",
      "batch 600\t-\tLoss: 1.2139\t-\tAccuracy: 0.219\n",
      "batch 900\t-\tLoss: 1.2107\t-\tAccuracy: 0.344\n",
      "batch 1200\t-\tLoss: 1.2102\t-\tAccuracy: 0.484\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 4\n",
      "batch 0\t-\tLoss: 1.2125\t-\tAccuracy: 0.312\n",
      "batch 300\t-\tLoss: 1.2128\t-\tAccuracy: 0.266\n",
      "batch 600\t-\tLoss: 1.2112\t-\tAccuracy: 0.375\n",
      "batch 900\t-\tLoss: 1.2126\t-\tAccuracy: 0.297\n",
      "batch 1200\t-\tLoss: 1.2107\t-\tAccuracy: 0.359\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 5\n",
      "batch 0\t-\tLoss: 1.2118\t-\tAccuracy: 0.266\n",
      "batch 300\t-\tLoss: 1.2087\t-\tAccuracy: 0.422\n",
      "batch 600\t-\tLoss: 1.2106\t-\tAccuracy: 0.359\n",
      "batch 900\t-\tLoss: 1.2118\t-\tAccuracy: 0.266\n",
      "batch 1200\t-\tLoss: 1.2108\t-\tAccuracy: 0.297\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 6\n",
      "batch 0\t-\tLoss: 1.2100\t-\tAccuracy: 0.312\n",
      "batch 300\t-\tLoss: 1.2091\t-\tAccuracy: 0.375\n",
      "batch 600\t-\tLoss: 1.2085\t-\tAccuracy: 0.359\n",
      "batch 900\t-\tLoss: 1.2097\t-\tAccuracy: 0.312\n",
      "batch 1200\t-\tLoss: 1.2077\t-\tAccuracy: 0.375\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 7\n",
      "batch 0\t-\tLoss: 1.2089\t-\tAccuracy: 0.312\n",
      "batch 300\t-\tLoss: 1.2086\t-\tAccuracy: 0.328\n",
      "batch 600\t-\tLoss: 1.2088\t-\tAccuracy: 0.281\n",
      "batch 900\t-\tLoss: 1.2075\t-\tAccuracy: 0.375\n",
      "batch 1200\t-\tLoss: 1.2064\t-\tAccuracy: 0.328\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 8\n",
      "batch 0\t-\tLoss: 1.2047\t-\tAccuracy: 0.469\n",
      "batch 300\t-\tLoss: 1.2062\t-\tAccuracy: 0.344\n",
      "batch 600\t-\tLoss: 1.2080\t-\tAccuracy: 0.234\n",
      "batch 900\t-\tLoss: 1.2058\t-\tAccuracy: 0.344\n",
      "batch 1200\t-\tLoss: 1.2056\t-\tAccuracy: 0.328\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 9\n",
      "batch 0\t-\tLoss: 1.2048\t-\tAccuracy: 0.516\n",
      "batch 300\t-\tLoss: 1.2048\t-\tAccuracy: 0.406\n",
      "batch 600\t-\tLoss: 1.2048\t-\tAccuracy: 0.344\n",
      "batch 900\t-\tLoss: 1.2053\t-\tAccuracy: 0.297\n",
      "batch 1200\t-\tLoss: 1.2042\t-\tAccuracy: 0.438\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 10\n",
      "batch 0\t-\tLoss: 1.2049\t-\tAccuracy: 0.250\n",
      "batch 300\t-\tLoss: 1.2045\t-\tAccuracy: 0.312\n",
      "batch 600\t-\tLoss: 1.2041\t-\tAccuracy: 0.359\n",
      "batch 900\t-\tLoss: 1.2053\t-\tAccuracy: 0.297\n",
      "batch 1200\t-\tLoss: 1.2029\t-\tAccuracy: 0.375\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 11\n",
      "batch 0\t-\tLoss: 1.2041\t-\tAccuracy: 0.281\n",
      "batch 300\t-\tLoss: 1.2040\t-\tAccuracy: 0.297\n",
      "batch 600\t-\tLoss: 1.2033\t-\tAccuracy: 0.391\n",
      "batch 900\t-\tLoss: 1.2033\t-\tAccuracy: 0.328\n",
      "batch 1200\t-\tLoss: 1.2039\t-\tAccuracy: 0.281\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 12\n",
      "batch 0\t-\tLoss: 1.2050\t-\tAccuracy: 0.312\n",
      "batch 300\t-\tLoss: 1.2031\t-\tAccuracy: 0.344\n",
      "batch 600\t-\tLoss: 1.2036\t-\tAccuracy: 0.266\n",
      "batch 900\t-\tLoss: 1.2026\t-\tAccuracy: 0.328\n",
      "batch 1200\t-\tLoss: 1.2023\t-\tAccuracy: 0.391\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 13\n",
      "batch 0\t-\tLoss: 1.2027\t-\tAccuracy: 0.344\n",
      "batch 300\t-\tLoss: 1.2042\t-\tAccuracy: 0.250\n",
      "batch 600\t-\tLoss: 1.2027\t-\tAccuracy: 0.359\n",
      "batch 900\t-\tLoss: 1.2050\t-\tAccuracy: 0.250\n",
      "batch 1200\t-\tLoss: 1.2021\t-\tAccuracy: 0.375\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 14\n",
      "batch 0\t-\tLoss: 1.2028\t-\tAccuracy: 0.359\n",
      "batch 300\t-\tLoss: 1.2035\t-\tAccuracy: 0.312\n",
      "batch 600\t-\tLoss: 1.2028\t-\tAccuracy: 0.281\n",
      "batch 900\t-\tLoss: 1.2021\t-\tAccuracy: 0.344\n",
      "batch 1200\t-\tLoss: 1.2019\t-\tAccuracy: 0.438\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 15\n",
      "batch 0\t-\tLoss: 1.2032\t-\tAccuracy: 0.297\n",
      "batch 300\t-\tLoss: 1.2011\t-\tAccuracy: 0.469\n",
      "batch 600\t-\tLoss: 1.2011\t-\tAccuracy: 0.359\n",
      "batch 900\t-\tLoss: 1.2027\t-\tAccuracy: 0.312\n",
      "batch 1200\t-\tLoss: 1.2033\t-\tAccuracy: 0.344\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 16\n",
      "batch 0\t-\tLoss: 1.2029\t-\tAccuracy: 0.375\n",
      "batch 300\t-\tLoss: 1.2029\t-\tAccuracy: 0.297\n",
      "batch 600\t-\tLoss: 1.2011\t-\tAccuracy: 0.406\n",
      "batch 900\t-\tLoss: 1.2021\t-\tAccuracy: 0.344\n",
      "batch 1200\t-\tLoss: 1.2026\t-\tAccuracy: 0.328\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 17\n",
      "batch 0\t-\tLoss: 1.2027\t-\tAccuracy: 0.391\n",
      "batch 300\t-\tLoss: 1.2027\t-\tAccuracy: 0.328\n",
      "batch 600\t-\tLoss: 1.2030\t-\tAccuracy: 0.328\n",
      "batch 900\t-\tLoss: 1.2028\t-\tAccuracy: 0.328\n",
      "batch 1200\t-\tLoss: 1.2037\t-\tAccuracy: 0.250\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 18\n",
      "batch 0\t-\tLoss: 1.2030\t-\tAccuracy: 0.406\n",
      "batch 300\t-\tLoss: 1.2013\t-\tAccuracy: 0.422\n",
      "batch 600\t-\tLoss: 1.2016\t-\tAccuracy: 0.406\n",
      "batch 900\t-\tLoss: 1.2026\t-\tAccuracy: 0.297\n",
      "batch 1200\t-\tLoss: 1.2032\t-\tAccuracy: 0.250\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 19\n",
      "batch 0\t-\tLoss: 1.2024\t-\tAccuracy: 0.344\n",
      "batch 300\t-\tLoss: 1.2013\t-\tAccuracy: 0.375\n",
      "batch 600\t-\tLoss: 1.2044\t-\tAccuracy: 0.234\n",
      "batch 900\t-\tLoss: 1.2019\t-\tAccuracy: 0.375\n",
      "batch 1200\t-\tLoss: 1.2032\t-\tAccuracy: 0.312\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 20\n",
      "batch 0\t-\tLoss: 1.2022\t-\tAccuracy: 0.328\n",
      "batch 300\t-\tLoss: 1.2033\t-\tAccuracy: 0.281\n",
      "batch 600\t-\tLoss: 1.2024\t-\tAccuracy: 0.344\n",
      "batch 900\t-\tLoss: 1.2023\t-\tAccuracy: 0.391\n",
      "batch 1200\t-\tLoss: 1.2032\t-\tAccuracy: 0.297\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 21\n",
      "batch 0\t-\tLoss: 1.2025\t-\tAccuracy: 0.344\n",
      "batch 300\t-\tLoss: 1.2024\t-\tAccuracy: 0.359\n",
      "batch 600\t-\tLoss: 1.2035\t-\tAccuracy: 0.297\n",
      "batch 900\t-\tLoss: 1.2029\t-\tAccuracy: 0.281\n",
      "batch 1200\t-\tLoss: 1.2025\t-\tAccuracy: 0.359\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 22\n",
      "batch 0\t-\tLoss: 1.2029\t-\tAccuracy: 0.234\n",
      "batch 300\t-\tLoss: 1.2041\t-\tAccuracy: 0.328\n",
      "batch 600\t-\tLoss: 1.2029\t-\tAccuracy: 0.266\n",
      "batch 900\t-\tLoss: 1.2049\t-\tAccuracy: 0.219\n",
      "batch 1200\t-\tLoss: 1.2025\t-\tAccuracy: 0.375\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 23\n",
      "batch 0\t-\tLoss: 1.2025\t-\tAccuracy: 0.328\n",
      "batch 300\t-\tLoss: 1.2027\t-\tAccuracy: 0.297\n",
      "batch 600\t-\tLoss: 1.2029\t-\tAccuracy: 0.312\n",
      "batch 900\t-\tLoss: 1.2024\t-\tAccuracy: 0.391\n",
      "batch 1200\t-\tLoss: 1.2023\t-\tAccuracy: 0.328\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 24\n",
      "batch 0\t-\tLoss: 1.2026\t-\tAccuracy: 0.328\n",
      "batch 300\t-\tLoss: 1.2009\t-\tAccuracy: 0.438\n",
      "batch 600\t-\tLoss: 1.2025\t-\tAccuracy: 0.328\n",
      "batch 900\t-\tLoss: 1.2026\t-\tAccuracy: 0.438\n",
      "batch 1200\t-\tLoss: 1.2022\t-\tAccuracy: 0.344\n",
      "Test\t-\tAccuracy: 0.337\n",
      "================================================================================\n",
      "Epoch 25\n",
      "batch 0\t-\tLoss: 1.2031\t-\tAccuracy: 0.297\n",
      "batch 300\t-\tLoss: 1.2026\t-\tAccuracy: 0.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 600\t-\tLoss: 1.2024\t-\tAccuracy: 0.375\n",
      "batch 900\t-\tLoss: 1.2021\t-\tAccuracy: 0.344\n",
      "batch 1200\t-\tLoss: 1.2024\t-\tAccuracy: 0.328\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 26\n",
      "batch 0\t-\tLoss: 1.2023\t-\tAccuracy: 0.391\n",
      "batch 300\t-\tLoss: 1.2017\t-\tAccuracy: 0.328\n",
      "batch 600\t-\tLoss: 1.2026\t-\tAccuracy: 0.375\n",
      "batch 900\t-\tLoss: 1.2025\t-\tAccuracy: 0.266\n",
      "batch 1200\t-\tLoss: 1.2028\t-\tAccuracy: 0.312\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 27\n",
      "batch 0\t-\tLoss: 1.2028\t-\tAccuracy: 0.312\n",
      "batch 300\t-\tLoss: 1.2037\t-\tAccuracy: 0.281\n",
      "batch 600\t-\tLoss: 1.2018\t-\tAccuracy: 0.391\n",
      "batch 900\t-\tLoss: 1.2025\t-\tAccuracy: 0.328\n",
      "batch 1200\t-\tLoss: 1.2036\t-\tAccuracy: 0.281\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 28\n",
      "batch 0\t-\tLoss: 1.2039\t-\tAccuracy: 0.234\n",
      "batch 300\t-\tLoss: 1.2039\t-\tAccuracy: 0.250\n",
      "batch 600\t-\tLoss: 1.2033\t-\tAccuracy: 0.250\n",
      "batch 900\t-\tLoss: 1.2025\t-\tAccuracy: 0.344\n",
      "batch 1200\t-\tLoss: 1.2031\t-\tAccuracy: 0.312\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 29\n",
      "batch 0\t-\tLoss: 1.2030\t-\tAccuracy: 0.281\n",
      "batch 300\t-\tLoss: 1.2030\t-\tAccuracy: 0.281\n",
      "batch 600\t-\tLoss: 1.2021\t-\tAccuracy: 0.375\n",
      "batch 900\t-\tLoss: 1.2015\t-\tAccuracy: 0.469\n",
      "batch 1200\t-\tLoss: 1.2037\t-\tAccuracy: 0.250\n",
      "Test\t-\tAccuracy: 0.331\n",
      "================================================================================\n",
      "Epoch 30\n",
      "batch 0\t-\tLoss: 1.2029\t-\tAccuracy: 0.297\n",
      "batch 300\t-\tLoss: 1.2023\t-\tAccuracy: 0.375\n",
      "batch 600\t-\tLoss: 1.2035\t-\tAccuracy: 0.281\n",
      "batch 900\t-\tLoss: 1.2029\t-\tAccuracy: 0.359\n",
      "batch 1200\t-\tLoss: 1.2040\t-\tAccuracy: 0.281\n",
      "Test\t-\tAccuracy: 0.332\n",
      "================================================================================\n",
      "Epoch 31\n",
      "batch 0\t-\tLoss: 1.2015\t-\tAccuracy: 0.391\n",
      "batch 300\t-\tLoss: 1.1549\t-\tAccuracy: 0.531\n",
      "batch 600\t-\tLoss: 1.0913\t-\tAccuracy: 0.531\n",
      "batch 900\t-\tLoss: 1.0350\t-\tAccuracy: 0.594\n",
      "batch 1200\t-\tLoss: 0.9870\t-\tAccuracy: 0.703\n",
      "Test\t-\tAccuracy: 0.662\n",
      "================================================================================\n",
      "Epoch 32\n",
      "batch 0\t-\tLoss: 0.9547\t-\tAccuracy: 0.703\n",
      "batch 300\t-\tLoss: 0.9039\t-\tAccuracy: 0.688\n",
      "batch 600\t-\tLoss: 0.8187\t-\tAccuracy: 0.750\n",
      "batch 900\t-\tLoss: 0.7614\t-\tAccuracy: 0.797\n",
      "batch 1200\t-\tLoss: 0.8748\t-\tAccuracy: 0.750\n",
      "Test\t-\tAccuracy: 0.782\n",
      "================================================================================\n",
      "Epoch 33\n",
      "batch 0\t-\tLoss: 0.7515\t-\tAccuracy: 0.797\n",
      "batch 300\t-\tLoss: 0.7361\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.7137\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.7716\t-\tAccuracy: 0.766\n",
      "batch 1200\t-\tLoss: 0.8063\t-\tAccuracy: 0.781\n",
      "Test\t-\tAccuracy: 0.839\n",
      "================================================================================\n",
      "Epoch 34\n",
      "batch 0\t-\tLoss: 0.6273\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.7497\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.4917\t-\tAccuracy: 0.953\n",
      "batch 900\t-\tLoss: 0.7190\t-\tAccuracy: 0.828\n",
      "batch 1200\t-\tLoss: 0.6995\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.849\n",
      "================================================================================\n",
      "Epoch 35\n",
      "batch 0\t-\tLoss: 0.7722\t-\tAccuracy: 0.797\n",
      "batch 300\t-\tLoss: 0.6444\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.7736\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.5858\t-\tAccuracy: 0.891\n",
      "batch 1200\t-\tLoss: 0.6337\t-\tAccuracy: 0.922\n",
      "Test\t-\tAccuracy: 0.854\n",
      "================================================================================\n",
      "Epoch 36\n",
      "batch 0\t-\tLoss: 0.6091\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.8173\t-\tAccuracy: 0.781\n",
      "batch 600\t-\tLoss: 0.6778\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.6737\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.6923\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.857\n",
      "================================================================================\n",
      "Epoch 37\n",
      "batch 0\t-\tLoss: 0.5109\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.6799\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.4536\t-\tAccuracy: 0.938\n",
      "batch 900\t-\tLoss: 0.7055\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.6167\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.858\n",
      "================================================================================\n",
      "Epoch 38\n",
      "batch 0\t-\tLoss: 0.5719\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.5065\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.6349\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.7413\t-\tAccuracy: 0.797\n",
      "batch 1200\t-\tLoss: 0.5239\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.858\n",
      "================================================================================\n",
      "Epoch 39\n",
      "batch 0\t-\tLoss: 0.5116\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.6721\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.5882\t-\tAccuracy: 0.891\n",
      "batch 900\t-\tLoss: 0.6093\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5583\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.858\n",
      "================================================================================\n",
      "Epoch 40\n",
      "batch 0\t-\tLoss: 0.6398\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.5243\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.6261\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.7047\t-\tAccuracy: 0.781\n",
      "batch 1200\t-\tLoss: 0.6136\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.858\n",
      "================================================================================\n",
      "Epoch 41\n",
      "batch 0\t-\tLoss: 0.6841\t-\tAccuracy: 0.766\n",
      "batch 300\t-\tLoss: 0.5263\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.6490\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.4702\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.5564\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.862\n",
      "================================================================================\n",
      "Epoch 42\n",
      "batch 0\t-\tLoss: 0.6343\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.7430\t-\tAccuracy: 0.766\n",
      "batch 600\t-\tLoss: 0.5866\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.6135\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.6459\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.860\n",
      "================================================================================\n",
      "Epoch 43\n",
      "batch 0\t-\tLoss: 0.5451\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.5431\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.4889\t-\tAccuracy: 0.922\n",
      "batch 900\t-\tLoss: 0.5962\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.6769\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.860\n",
      "================================================================================\n",
      "Epoch 44\n",
      "batch 0\t-\tLoss: 0.4662\t-\tAccuracy: 0.938\n",
      "batch 300\t-\tLoss: 0.5077\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.5158\t-\tAccuracy: 0.906\n",
      "batch 900\t-\tLoss: 0.6271\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.5983\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.862\n",
      "================================================================================\n",
      "Epoch 45\n",
      "batch 0\t-\tLoss: 0.6349\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.4306\t-\tAccuracy: 0.938\n",
      "batch 600\t-\tLoss: 0.6346\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.4811\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.5210\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.860\n",
      "================================================================================\n",
      "Epoch 46\n",
      "batch 0\t-\tLoss: 0.7257\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.6842\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.6046\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.5022\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.8423\t-\tAccuracy: 0.750\n",
      "Test\t-\tAccuracy: 0.866\n",
      "================================================================================\n",
      "Epoch 47\n",
      "batch 0\t-\tLoss: 0.6015\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5113\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.6983\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.6057\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.5807\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.866\n",
      "================================================================================\n",
      "Epoch 48\n",
      "batch 0\t-\tLoss: 0.6015\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.8663\t-\tAccuracy: 0.734\n",
      "batch 600\t-\tLoss: 0.4941\t-\tAccuracy: 0.953\n",
      "batch 900\t-\tLoss: 0.6496\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.4721\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.865\n",
      "================================================================================\n",
      "Epoch 49\n",
      "batch 0\t-\tLoss: 0.5911\t-\tAccuracy: 0.906\n",
      "batch 300\t-\tLoss: 0.6350\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.6489\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.6493\t-\tAccuracy: 0.781\n",
      "batch 1200\t-\tLoss: 0.6806\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.867\n",
      "================================================================================\n",
      "Epoch 50\n",
      "batch 0\t-\tLoss: 0.6644\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.5669\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.4719\t-\tAccuracy: 0.906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 900\t-\tLoss: 0.7577\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.7314\t-\tAccuracy: 0.797\n",
      "Test\t-\tAccuracy: 0.870\n",
      "================================================================================\n",
      "Epoch 51\n",
      "batch 0\t-\tLoss: 0.5997\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.7082\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.5661\t-\tAccuracy: 0.906\n",
      "batch 900\t-\tLoss: 0.4429\t-\tAccuracy: 0.938\n",
      "batch 1200\t-\tLoss: 0.6192\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.869\n",
      "================================================================================\n",
      "Epoch 52\n",
      "batch 0\t-\tLoss: 0.4859\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.5998\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.7785\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.5537\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.4694\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.870\n",
      "================================================================================\n",
      "Epoch 53\n",
      "batch 0\t-\tLoss: 0.6973\t-\tAccuracy: 0.797\n",
      "batch 300\t-\tLoss: 0.4566\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.5388\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.5372\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.5103\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.871\n",
      "================================================================================\n",
      "Epoch 54\n",
      "batch 0\t-\tLoss: 0.6151\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.8352\t-\tAccuracy: 0.750\n",
      "batch 600\t-\tLoss: 0.4862\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.6457\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.6701\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.869\n",
      "================================================================================\n",
      "Epoch 55\n",
      "batch 0\t-\tLoss: 0.4784\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.6001\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.5629\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.5016\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.7609\t-\tAccuracy: 0.797\n",
      "Test\t-\tAccuracy: 0.868\n",
      "================================================================================\n",
      "Epoch 56\n",
      "batch 0\t-\tLoss: 0.5238\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.6416\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.4929\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.6301\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.5548\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.870\n",
      "================================================================================\n",
      "Epoch 57\n",
      "batch 0\t-\tLoss: 0.6738\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.6535\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.5565\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.6887\t-\tAccuracy: 0.828\n",
      "batch 1200\t-\tLoss: 0.5271\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.869\n",
      "================================================================================\n",
      "Epoch 58\n",
      "batch 0\t-\tLoss: 0.4755\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.5734\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.6976\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.6023\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.5241\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.869\n",
      "================================================================================\n",
      "Epoch 59\n",
      "batch 0\t-\tLoss: 0.6990\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.5051\t-\tAccuracy: 0.875\n",
      "batch 600\t-\tLoss: 0.5119\t-\tAccuracy: 0.891\n",
      "batch 900\t-\tLoss: 0.5316\t-\tAccuracy: 0.922\n",
      "batch 1200\t-\tLoss: 0.4711\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.872\n",
      "================================================================================\n",
      "Epoch 60\n",
      "batch 0\t-\tLoss: 0.8200\t-\tAccuracy: 0.750\n",
      "batch 300\t-\tLoss: 0.6109\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.7680\t-\tAccuracy: 0.766\n",
      "batch 900\t-\tLoss: 0.7369\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.6573\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.871\n",
      "================================================================================\n",
      "Epoch 61\n",
      "batch 0\t-\tLoss: 0.6672\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.8961\t-\tAccuracy: 0.703\n",
      "batch 600\t-\tLoss: 0.4890\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.7516\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.5039\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.869\n",
      "================================================================================\n",
      "Epoch 62\n",
      "batch 0\t-\tLoss: 0.5556\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.6147\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.5750\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.5653\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5196\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.871\n",
      "================================================================================\n",
      "Epoch 63\n",
      "batch 0\t-\tLoss: 0.5602\t-\tAccuracy: 0.906\n",
      "batch 300\t-\tLoss: 0.7132\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.4863\t-\tAccuracy: 0.922\n",
      "batch 900\t-\tLoss: 0.4067\t-\tAccuracy: 0.938\n",
      "batch 1200\t-\tLoss: 0.6436\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.870\n",
      "================================================================================\n",
      "Epoch 64\n",
      "batch 0\t-\tLoss: 0.5130\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.5926\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.6491\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.6633\t-\tAccuracy: 0.828\n",
      "batch 1200\t-\tLoss: 0.3063\t-\tAccuracy: 0.984\n",
      "Test\t-\tAccuracy: 0.871\n",
      "================================================================================\n",
      "Epoch 65\n",
      "batch 0\t-\tLoss: 0.6207\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.6636\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.4524\t-\tAccuracy: 0.891\n",
      "batch 900\t-\tLoss: 0.5015\t-\tAccuracy: 0.922\n",
      "batch 1200\t-\tLoss: 0.5745\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 66\n",
      "batch 0\t-\tLoss: 0.6160\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.4981\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.6785\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.4915\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.5752\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 67\n",
      "batch 0\t-\tLoss: 0.5093\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.6963\t-\tAccuracy: 0.766\n",
      "batch 600\t-\tLoss: 0.5956\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.5810\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5239\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.872\n",
      "================================================================================\n",
      "Epoch 68\n",
      "batch 0\t-\tLoss: 0.7121\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.7206\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.5606\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.6265\t-\tAccuracy: 0.828\n",
      "batch 1200\t-\tLoss: 0.6189\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 69\n",
      "batch 0\t-\tLoss: 0.7088\t-\tAccuracy: 0.797\n",
      "batch 300\t-\tLoss: 0.4844\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.4761\t-\tAccuracy: 0.922\n",
      "batch 900\t-\tLoss: 0.6024\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.6110\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.873\n",
      "================================================================================\n",
      "Epoch 70\n",
      "batch 0\t-\tLoss: 0.6410\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.5122\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.4346\t-\tAccuracy: 0.906\n",
      "batch 900\t-\tLoss: 0.6475\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.5048\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.873\n",
      "================================================================================\n",
      "Epoch 71\n",
      "batch 0\t-\tLoss: 0.5746\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5905\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.6236\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.6337\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.4702\t-\tAccuracy: 0.922\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 72\n",
      "batch 0\t-\tLoss: 0.6604\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.6309\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.4270\t-\tAccuracy: 0.953\n",
      "batch 900\t-\tLoss: 0.4550\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.7135\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 73\n",
      "batch 0\t-\tLoss: 0.5445\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5970\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.5438\t-\tAccuracy: 0.891\n",
      "batch 900\t-\tLoss: 0.4697\t-\tAccuracy: 0.922\n",
      "batch 1200\t-\tLoss: 0.4858\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 74\n",
      "batch 0\t-\tLoss: 0.5308\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.4192\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.6305\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.5385\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.7831\t-\tAccuracy: 0.781\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 75\n",
      "batch 0\t-\tLoss: 0.5706\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.5957\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.6249\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.5317\t-\tAccuracy: 0.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1200\t-\tLoss: 0.5225\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 76\n",
      "batch 0\t-\tLoss: 0.4867\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.4954\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.7341\t-\tAccuracy: 0.797\n",
      "batch 900\t-\tLoss: 0.4521\t-\tAccuracy: 0.938\n",
      "batch 1200\t-\tLoss: 0.6333\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 77\n",
      "batch 0\t-\tLoss: 0.6193\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.5902\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.8594\t-\tAccuracy: 0.734\n",
      "batch 900\t-\tLoss: 0.6226\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.3758\t-\tAccuracy: 0.969\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 78\n",
      "batch 0\t-\tLoss: 0.7579\t-\tAccuracy: 0.797\n",
      "batch 300\t-\tLoss: 0.6929\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.6375\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.3873\t-\tAccuracy: 0.938\n",
      "batch 1200\t-\tLoss: 0.6236\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.873\n",
      "================================================================================\n",
      "Epoch 79\n",
      "batch 0\t-\tLoss: 0.4548\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.6462\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.5642\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.5868\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.6143\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 80\n",
      "batch 0\t-\tLoss: 0.6022\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.5018\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.6900\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.4606\t-\tAccuracy: 0.953\n",
      "batch 1200\t-\tLoss: 0.5793\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 81\n",
      "batch 0\t-\tLoss: 0.7888\t-\tAccuracy: 0.781\n",
      "batch 300\t-\tLoss: 0.5312\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.6513\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.5457\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.7072\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 82\n",
      "batch 0\t-\tLoss: 0.5938\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.5002\t-\tAccuracy: 0.875\n",
      "batch 600\t-\tLoss: 0.4970\t-\tAccuracy: 0.906\n",
      "batch 900\t-\tLoss: 0.5347\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.4989\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 83\n",
      "batch 0\t-\tLoss: 0.4814\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.5181\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.5519\t-\tAccuracy: 0.906\n",
      "batch 900\t-\tLoss: 0.6188\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.6042\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 84\n",
      "batch 0\t-\tLoss: 0.6552\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.6697\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.6839\t-\tAccuracy: 0.797\n",
      "batch 900\t-\tLoss: 0.4647\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.4789\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 85\n",
      "batch 0\t-\tLoss: 0.3450\t-\tAccuracy: 0.953\n",
      "batch 300\t-\tLoss: 0.5455\t-\tAccuracy: 0.875\n",
      "batch 600\t-\tLoss: 0.6164\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.4545\t-\tAccuracy: 0.922\n",
      "batch 1200\t-\tLoss: 0.6643\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 86\n",
      "batch 0\t-\tLoss: 0.5158\t-\tAccuracy: 0.906\n",
      "batch 300\t-\tLoss: 0.5694\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.5828\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.4234\t-\tAccuracy: 0.938\n",
      "batch 1200\t-\tLoss: 0.5933\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 87\n",
      "batch 0\t-\tLoss: 0.5959\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5425\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.5614\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.5963\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.4542\t-\tAccuracy: 0.922\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 88\n",
      "batch 0\t-\tLoss: 0.5229\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.7320\t-\tAccuracy: 0.766\n",
      "batch 600\t-\tLoss: 0.4487\t-\tAccuracy: 0.922\n",
      "batch 900\t-\tLoss: 0.5051\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.5172\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 89\n",
      "batch 0\t-\tLoss: 0.4588\t-\tAccuracy: 0.906\n",
      "batch 300\t-\tLoss: 0.5761\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.5948\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.4893\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.5289\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 90\n",
      "batch 0\t-\tLoss: 0.4299\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.6529\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.6457\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.6070\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.6517\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 91\n",
      "batch 0\t-\tLoss: 0.7856\t-\tAccuracy: 0.781\n",
      "batch 300\t-\tLoss: 0.7381\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.5456\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.5134\t-\tAccuracy: 0.891\n",
      "batch 1200\t-\tLoss: 0.4511\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 92\n",
      "batch 0\t-\tLoss: 0.4929\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.5189\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.5568\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.5030\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.3926\t-\tAccuracy: 0.953\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 93\n",
      "batch 0\t-\tLoss: 0.6032\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.4802\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.6168\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.4954\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.5281\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 94\n",
      "batch 0\t-\tLoss: 0.4508\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.4338\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.7357\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.4897\t-\tAccuracy: 0.891\n",
      "batch 1200\t-\tLoss: 0.5910\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 95\n",
      "batch 0\t-\tLoss: 0.5968\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.5065\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.6638\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.4688\t-\tAccuracy: 0.891\n",
      "batch 1200\t-\tLoss: 0.4128\t-\tAccuracy: 0.922\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 96\n",
      "batch 0\t-\tLoss: 0.5763\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.3886\t-\tAccuracy: 0.953\n",
      "batch 600\t-\tLoss: 0.4730\t-\tAccuracy: 0.891\n",
      "batch 900\t-\tLoss: 0.5383\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.4829\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 97\n",
      "batch 0\t-\tLoss: 0.4519\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.4814\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.8150\t-\tAccuracy: 0.734\n",
      "batch 900\t-\tLoss: 0.6073\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.5700\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 98\n",
      "batch 0\t-\tLoss: 0.3496\t-\tAccuracy: 0.953\n",
      "batch 300\t-\tLoss: 0.6541\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.5605\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.4783\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.4692\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.872\n",
      "================================================================================\n",
      "Epoch 99\n",
      "batch 0\t-\tLoss: 0.6414\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.4139\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.7775\t-\tAccuracy: 0.781\n",
      "batch 900\t-\tLoss: 0.6085\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.5098\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.873\n",
      "================================================================================\n",
      "Epoch 100\n",
      "batch 0\t-\tLoss: 0.5613\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.5683\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.6052\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.5801\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5499\t-\tAccuracy: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 101\n",
      "batch 0\t-\tLoss: 0.6391\t-\tAccuracy: 0.844\n",
      "batch 300\t-\tLoss: 0.4152\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.7285\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.6573\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.6409\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 102\n",
      "batch 0\t-\tLoss: 0.4731\t-\tAccuracy: 0.906\n",
      "batch 300\t-\tLoss: 0.4985\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.6422\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.4054\t-\tAccuracy: 0.953\n",
      "batch 1200\t-\tLoss: 0.5426\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 103\n",
      "batch 0\t-\tLoss: 0.6476\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.6655\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.6641\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.5783\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.7779\t-\tAccuracy: 0.781\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 104\n",
      "batch 0\t-\tLoss: 0.6584\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5770\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.6361\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.7566\t-\tAccuracy: 0.766\n",
      "batch 1200\t-\tLoss: 0.4673\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.875\n",
      "================================================================================\n",
      "Epoch 105\n",
      "batch 0\t-\tLoss: 0.6728\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.5502\t-\tAccuracy: 0.875\n",
      "batch 600\t-\tLoss: 0.6899\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.5057\t-\tAccuracy: 0.891\n",
      "batch 1200\t-\tLoss: 0.6744\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.874\n",
      "================================================================================\n",
      "Epoch 106\n",
      "batch 0\t-\tLoss: 0.5584\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.5198\t-\tAccuracy: 0.922\n",
      "batch 600\t-\tLoss: 0.4434\t-\tAccuracy: 0.922\n",
      "batch 900\t-\tLoss: 0.6144\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.7334\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.873\n",
      "================================================================================\n",
      "Epoch 107\n",
      "batch 0\t-\tLoss: 0.4527\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.6018\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.5196\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.6303\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.6191\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.873\n",
      "================================================================================\n",
      "Epoch 108\n",
      "batch 0\t-\tLoss: 0.5922\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5863\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.7627\t-\tAccuracy: 0.781\n",
      "batch 900\t-\tLoss: 0.5688\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.6744\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.872\n",
      "================================================================================\n",
      "Epoch 109\n",
      "batch 0\t-\tLoss: 0.5829\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.5213\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.6920\t-\tAccuracy: 0.766\n",
      "batch 900\t-\tLoss: 0.5059\t-\tAccuracy: 0.891\n",
      "batch 1200\t-\tLoss: 0.5267\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.872\n",
      "================================================================================\n",
      "Epoch 110\n",
      "batch 0\t-\tLoss: 0.4743\t-\tAccuracy: 0.906\n",
      "batch 300\t-\tLoss: 0.6071\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.6215\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.7144\t-\tAccuracy: 0.781\n",
      "batch 1200\t-\tLoss: 0.5884\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.876\n",
      "================================================================================\n",
      "Epoch 111\n",
      "batch 0\t-\tLoss: 0.7347\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.6058\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.6156\t-\tAccuracy: 0.844\n",
      "batch 900\t-\tLoss: 0.5118\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5359\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.872\n",
      "================================================================================\n",
      "Epoch 112\n",
      "batch 0\t-\tLoss: 0.4048\t-\tAccuracy: 0.938\n",
      "batch 300\t-\tLoss: 0.4820\t-\tAccuracy: 0.891\n",
      "batch 600\t-\tLoss: 0.5176\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.4634\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.5112\t-\tAccuracy: 0.891\n",
      "Test\t-\tAccuracy: 0.873\n",
      "================================================================================\n",
      "Epoch 113\n",
      "batch 0\t-\tLoss: 0.5734\t-\tAccuracy: 0.859\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-4b8618772a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_test_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, data_loader, verbose)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    print('Epoch {:d}'.format(epoch))\n",
    "    tree.train_epoch(train_loader)\n",
    "    tree.print_test_metrics(test_loader)\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6357875\n",
      "0.6321\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=4)\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "print(accuracy_score(y_train, dtc.predict(X_train)))\n",
    "print(accuracy_score(y_test, dtc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alpha', Parameter containing:\n",
       "  -28.4662\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.path_prob', Parameter containing:\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "  [torch.cuda.FloatTensor of size 64x1 (GPU 0)]),\n",
       " ('root.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.3347 -0.3486  0.8631  1.9828  1.4533  3.3023 -0.9128  0.1892  0.1414  1.8552\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "   1.1296 -0.2290  1.2782  1.8535 -0.2930 -2.0946  0.2256 -0.3678  2.7140  0.1783\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.fc.bias', Parameter containing:\n",
       "   0.2140\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "   0.6896 -0.0244  0.6173  1.3230 -3.2115 -1.5717 -0.0640 -0.5078 -0.5648 -1.2267\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -1.3404  0.4825  2.5981 -1.8665  0.3914  1.3304  2.4695  0.5407 -2.2936 -0.5937\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.left_child.fc.bias', Parameter containing:\n",
       "  -0.4663\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.left_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.1617  0.1071  0.8381  0.0286 -1.3975 -1.6004  0.7020  0.2966  0.3894 -2.4500\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -2.5325 -0.1842  1.3598 -1.7192 -0.0247 -0.5191 -0.8378  0.1075 -1.3631  0.3963\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.left_child.left_child.fc.bias', Parameter containing:\n",
       "  1.00000e-02 *\n",
       "   -5.7703\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.left_child.left_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.6874 -0.3691 -0.8489  2.0246  0.8602  1.5014 -1.4131  0.7034  0.5363 -0.3970\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -1.5499 -0.5099 -0.8246 -2.2957 -0.4371  1.8571 -0.2295 -0.4566  0.7926  0.5245\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.left_child.left_child.left_child.fc.bias', Parameter containing:\n",
       "   0.4443\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.left_child.left_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -1.1085\n",
       "  -0.4394\n",
       "   1.4907\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.left_child.left_child.left_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   1.8059\n",
       "  -2.3255\n",
       "  -0.1153\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.left_child.left_child.right_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "   0.7749 -0.0259 -0.8631  1.3192 -1.7045 -0.1122 -1.4985 -0.2906 -0.2523 -1.1947\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -2.1434  0.5547 -4.5394  1.1873  0.8648  2.1053  0.4845  0.8941 -1.3473 -0.2397\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.left_child.left_child.right_child.fc.bias', Parameter containing:\n",
       "  -0.8617\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.left_child.right_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -1.9498\n",
       "   0.2836\n",
       "  -0.4954\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.left_child.left_child.right_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   3.0669\n",
       "   0.0909\n",
       "  -0.8066\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.left_child.right_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.0089 -0.6208 -0.3865 -0.7179 -2.6182  0.2741  0.6806  0.2930  0.5203  1.2716\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "   1.8471 -0.3186  1.2129 -0.2718 -0.0877 -1.8393  1.6842  0.2475  0.0992  0.2394\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.left_child.right_child.fc.bias', Parameter containing:\n",
       "  -0.1468\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.right_child.left_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -1.0086  0.0321 -2.9675  1.6318 -1.4427  1.7882  0.9580  0.8801  0.8593  0.7513\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -2.5675 -0.9919 -1.0788 -0.6404 -1.0436 -1.4593 -1.2096 -1.0429  1.2795  0.9068\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.left_child.right_child.left_child.fc.bias', Parameter containing:\n",
       "   1.0310\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.right_child.left_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   1.9596\n",
       "   0.5477\n",
       "  -0.4630\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.left_child.right_child.left_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -0.3686\n",
       "   1.6170\n",
       "  -2.3674\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.left_child.right_child.right_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -1.2128  0.7764  1.8571 -0.6096 -0.4870  0.8305 -0.5898  1.6486  1.3263 -1.0532\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -0.2987 -1.4670 -1.2788  2.7887 -1.5251 -1.7522 -1.8603 -1.5193 -0.8482  1.3360\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.left_child.right_child.right_child.fc.bias', Parameter containing:\n",
       "   1.5136\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.right_child.right_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   1.8399\n",
       "   0.2481\n",
       "   0.3968\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.left_child.right_child.right_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -0.4323\n",
       "   2.0077\n",
       "  -0.4927\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.6414  0.5321 -2.8911  2.6472  1.0929  0.2584 -0.9815  0.5491  0.5268 -0.1737\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -1.3518 -0.5679 -0.4333 -2.5919 -0.5874  3.1820  0.4034 -0.6355  1.0531  0.5406\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.right_child.fc.bias', Parameter containing:\n",
       "   0.6832\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.left_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.1524  0.0531  0.4951  0.6445 -0.8429 -0.8943  1.8989 -0.0405  0.1489 -2.6096\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "   0.1898 -0.0877 -0.5427  2.4592 -0.4356 -1.1845  3.6813 -0.4686  2.5344  0.0772\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.right_child.left_child.fc.bias', Parameter containing:\n",
       "   0.4730\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.left_child.left_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -1.1555 -0.1420 -0.1569  0.5278 -0.1574 -0.9356  1.7314  0.8412  0.9750 -2.1512\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "   0.0716 -1.0732 -0.5771  1.3277 -1.5221 -0.4794  3.2038 -1.5358  2.0346  0.9271\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.right_child.left_child.left_child.fc.bias', Parameter containing:\n",
       "   1.4433\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.left_child.left_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -1.9055\n",
       "  -2.1100\n",
       "   2.0482\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.left_child.left_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -0.6883\n",
       "   0.8088\n",
       "   1.5099\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.left_child.right_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -1.4115  0.3166 -0.7470 -1.4993 -0.9720  1.7102 -1.6540  0.9712  1.1965  1.4369\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "   1.3789 -1.2822 -2.5131 -1.5442 -1.4357  1.1081 -1.8282 -1.4143 -2.3579  0.9887\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.right_child.left_child.right_child.fc.bias', Parameter containing:\n",
       "   1.4647\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.left_child.right_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -0.8187\n",
       "  -0.2482\n",
       "   1.6878\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.left_child.right_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -1.0616\n",
       "   2.1667\n",
       "  -0.4748\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.right_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.6455  0.1845  0.6888 -0.6325 -2.8077 -1.5983 -0.4698  0.5110  0.5165  2.2738\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "  -0.9052 -0.5209  2.4246 -0.6923 -0.6175 -0.8039 -0.5328 -0.5908 -1.5677  0.4793\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.right_child.right_child.fc.bias', Parameter containing:\n",
       "   0.5563\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.right_child.left_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.1055 -0.2053  1.7207  0.4461 -2.5324 -0.9886 -5.3199 -0.0136 -0.0945 -2.9284\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "   1.6412  0.0212 -1.7677 -1.0514 -0.1155 -0.6288 -2.0381 -0.1590  0.7075 -0.1561\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.right_child.right_child.left_child.fc.bias', Parameter containing:\n",
       "   0.1890\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.right_child.left_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -1.0735\n",
       "  -1.9920\n",
       "   1.7723\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.right_child.left_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   1.6109\n",
       "  -1.4385\n",
       "  -1.3918\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.right_child.right_child.fc.weight', Parameter containing:\n",
       "  \n",
       "  Columns 0 to 9 \n",
       "  -0.0440 -0.4155 -2.1756  0.0546 -0.8563 -1.3653  1.0311 -0.0588 -0.2665 -0.4563\n",
       "  \n",
       "  Columns 10 to 19 \n",
       "   0.0671  0.0018  0.6557 -0.1496 -0.0219  2.8068  2.8326 -0.0569  1.5201 -0.0516\n",
       "  [torch.cuda.FloatTensor of size 1x20 (GPU 0)]),\n",
       " ('root.right_child.right_child.right_child.fc.bias', Parameter containing:\n",
       "  1.00000e-02 *\n",
       "    4.2906\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.right_child.right_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -0.9274\n",
       "  -2.1321\n",
       "   0.5271\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('root.right_child.right_child.right_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   0.3098\n",
       "  -1.0944\n",
       "  -1.4562\n",
       "  [torch.cuda.FloatTensor of size 3 (GPU 0)]),\n",
       " ('bn.weight', Parameter containing:\n",
       "   0.0878\n",
       "   0.7317\n",
       "   3.8105\n",
       "   3.8048\n",
       "   4.6498\n",
       "   5.2624\n",
       "   4.2189\n",
       "   0.0259\n",
       "   0.0480\n",
       "   4.9631\n",
       "   4.1407\n",
       "  -0.0838\n",
       "   4.9819\n",
       "   5.2090\n",
       "  -0.0164\n",
       "   6.1190\n",
       "   5.1359\n",
       "   0.0741\n",
       "   4.9896\n",
       "   0.0178\n",
       "  [torch.cuda.FloatTensor of size 20 (GPU 0)]),\n",
       " ('bn.bias', Parameter containing:\n",
       "  -2.0350\n",
       "   0.7014\n",
       "  -0.2084\n",
       "   0.0624\n",
       "  -0.0516\n",
       "   0.7086\n",
       "  -0.3940\n",
       "   2.5129\n",
       "   2.5909\n",
       "   0.3088\n",
       "  -0.0751\n",
       "  -2.2499\n",
       "  -0.6751\n",
       "  -0.0634\n",
       "  -2.0518\n",
       "  -0.3554\n",
       "  -0.7189\n",
       "  -2.2105\n",
       "   0.0386\n",
       "   2.3868\n",
       "  [torch.cuda.FloatTensor of size 20 (GPU 0)])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tree.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_classes=2, n_informative=2, n_features=4, )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "train_loader = DataLoader(dataset=ExampleData(X_train, y_train),\n",
    "                          batch_size=64,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=ExampleData(X_test, y_test),\n",
    "                         batch_size=64,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = Arguments(max_depth=3, cuda=True, input_dim=4, output_dim=2, lmbda=0.1, lr=0.01, momentum=0,\n",
    "                 log_interval=100, epochs=200, l1_const=0.005\n",
    "                )\n",
    "\n",
    "tree = newmodel.SoftDecisionTree(args)\n",
    "tree.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "batch 0\t-\tLoss: 1.1151\t-\tAccuracy: 0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100\t-\tLoss: 1.1143\t-\tAccuracy: 0.422\n",
      "batch 200\t-\tLoss: 1.0435\t-\tAccuracy: 0.469\n",
      "batch 300\t-\tLoss: 0.9952\t-\tAccuracy: 0.500\n",
      "batch 400\t-\tLoss: 1.0272\t-\tAccuracy: 0.422\n",
      "batch 500\t-\tLoss: 0.9754\t-\tAccuracy: 0.469\n",
      "batch 600\t-\tLoss: 0.8997\t-\tAccuracy: 0.562\n",
      "batch 700\t-\tLoss: 0.9322\t-\tAccuracy: 0.484\n",
      "batch 800\t-\tLoss: 0.9353\t-\tAccuracy: 0.453\n",
      "batch 900\t-\tLoss: 0.9079\t-\tAccuracy: 0.484\n",
      "batch 1000\t-\tLoss: 0.9044\t-\tAccuracy: 0.469\n",
      "batch 1100\t-\tLoss: 0.9229\t-\tAccuracy: 0.406\n",
      "batch 1200\t-\tLoss: 0.9114\t-\tAccuracy: 0.406\n",
      "Test\t-\tAccuracy: 0.500\t-\tAUC ROC: 0.500\n",
      "================================================================================\n",
      "Epoch 1\n",
      "batch 0\t-\tLoss: 0.8240\t-\tAccuracy: 0.609\n",
      "batch 100\t-\tLoss: 0.8608\t-\tAccuracy: 0.500\n",
      "batch 200\t-\tLoss: 0.8708\t-\tAccuracy: 0.453\n",
      "batch 300\t-\tLoss: 0.8383\t-\tAccuracy: 0.531\n",
      "batch 400\t-\tLoss: 0.8178\t-\tAccuracy: 0.578\n",
      "batch 500\t-\tLoss: 0.8535\t-\tAccuracy: 0.453\n",
      "batch 600\t-\tLoss: 0.8058\t-\tAccuracy: 0.594\n",
      "batch 700\t-\tLoss: 0.8499\t-\tAccuracy: 0.422\n",
      "batch 800\t-\tLoss: 0.8374\t-\tAccuracy: 0.453\n",
      "batch 900\t-\tLoss: 0.8302\t-\tAccuracy: 0.469\n",
      "batch 1000\t-\tLoss: 0.8224\t-\tAccuracy: 0.500\n",
      "batch 1100\t-\tLoss: 0.8391\t-\tAccuracy: 0.406\n",
      "batch 1200\t-\tLoss: 0.8194\t-\tAccuracy: 0.469\n",
      "Test\t-\tAccuracy: 0.500\t-\tAUC ROC: 0.500\n",
      "================================================================================\n",
      "Epoch 2\n",
      "batch 0\t-\tLoss: 0.8132\t-\tAccuracy: 0.500\n",
      "batch 100\t-\tLoss: 0.8124\t-\tAccuracy: 0.484\n",
      "batch 200\t-\tLoss: 0.7939\t-\tAccuracy: 0.578\n",
      "batch 300\t-\tLoss: 0.8074\t-\tAccuracy: 0.484\n",
      "batch 400\t-\tLoss: 0.7941\t-\tAccuracy: 0.547\n",
      "batch 500\t-\tLoss: 0.8062\t-\tAccuracy: 0.469\n",
      "batch 600\t-\tLoss: 0.7966\t-\tAccuracy: 0.500\n",
      "batch 700\t-\tLoss: 0.8032\t-\tAccuracy: 0.484\n",
      "batch 800\t-\tLoss: 0.8083\t-\tAccuracy: 0.406\n",
      "batch 900\t-\tLoss: 0.7917\t-\tAccuracy: 0.531\n",
      "batch 1000\t-\tLoss: 0.7920\t-\tAccuracy: 0.531\n",
      "batch 1100\t-\tLoss: 0.7984\t-\tAccuracy: 0.469\n",
      "batch 1200\t-\tLoss: 0.7876\t-\tAccuracy: 0.562\n",
      "Test\t-\tAccuracy: 0.615\t-\tAUC ROC: 0.619\n",
      "================================================================================\n",
      "Epoch 3\n",
      "batch 0\t-\tLoss: 0.7993\t-\tAccuracy: 0.531\n",
      "batch 100\t-\tLoss: 0.7840\t-\tAccuracy: 0.656\n",
      "batch 200\t-\tLoss: 0.7830\t-\tAccuracy: 0.688\n",
      "batch 300\t-\tLoss: 0.7934\t-\tAccuracy: 0.625\n",
      "batch 400\t-\tLoss: 0.7809\t-\tAccuracy: 0.797\n",
      "batch 500\t-\tLoss: 0.7788\t-\tAccuracy: 0.750\n",
      "batch 600\t-\tLoss: 0.7793\t-\tAccuracy: 0.797\n",
      "batch 700\t-\tLoss: 0.7807\t-\tAccuracy: 0.719\n",
      "batch 800\t-\tLoss: 0.7859\t-\tAccuracy: 0.750\n",
      "batch 900\t-\tLoss: 0.7827\t-\tAccuracy: 0.719\n",
      "batch 1000\t-\tLoss: 0.7872\t-\tAccuracy: 0.688\n",
      "batch 1100\t-\tLoss: 0.7824\t-\tAccuracy: 0.781\n",
      "batch 1200\t-\tLoss: 0.7741\t-\tAccuracy: 0.812\n",
      "Test\t-\tAccuracy: 0.832\t-\tAUC ROC: 0.876\n",
      "================================================================================\n",
      "Epoch 4\n",
      "batch 0\t-\tLoss: 0.7756\t-\tAccuracy: 0.828\n",
      "batch 100\t-\tLoss: 0.7737\t-\tAccuracy: 0.797\n",
      "batch 200\t-\tLoss: 0.7706\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.7677\t-\tAccuracy: 0.875\n",
      "batch 400\t-\tLoss: 0.7674\t-\tAccuracy: 0.891\n",
      "batch 500\t-\tLoss: 0.7704\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.7651\t-\tAccuracy: 0.906\n",
      "batch 700\t-\tLoss: 0.7689\t-\tAccuracy: 0.859\n",
      "batch 800\t-\tLoss: 0.7684\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.7593\t-\tAccuracy: 0.906\n",
      "batch 1000\t-\tLoss: 0.7640\t-\tAccuracy: 0.812\n",
      "batch 1100\t-\tLoss: 0.7560\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.7565\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.878\n",
      "================================================================================\n",
      "Epoch 5\n",
      "batch 0\t-\tLoss: 0.7641\t-\tAccuracy: 0.828\n",
      "batch 100\t-\tLoss: 0.7480\t-\tAccuracy: 0.875\n",
      "batch 200\t-\tLoss: 0.7526\t-\tAccuracy: 0.828\n",
      "batch 300\t-\tLoss: 0.7523\t-\tAccuracy: 0.922\n",
      "batch 400\t-\tLoss: 0.7379\t-\tAccuracy: 0.875\n",
      "batch 500\t-\tLoss: 0.7428\t-\tAccuracy: 0.766\n",
      "batch 600\t-\tLoss: 0.7339\t-\tAccuracy: 0.875\n",
      "batch 700\t-\tLoss: 0.7315\t-\tAccuracy: 0.875\n",
      "batch 800\t-\tLoss: 0.7365\t-\tAccuracy: 0.781\n",
      "batch 900\t-\tLoss: 0.7249\t-\tAccuracy: 0.828\n",
      "batch 1000\t-\tLoss: 0.7013\t-\tAccuracy: 0.891\n",
      "batch 1100\t-\tLoss: 0.6936\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.6955\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.848\t-\tAUC ROC: 0.865\n",
      "================================================================================\n",
      "Epoch 6\n",
      "batch 0\t-\tLoss: 0.6910\t-\tAccuracy: 0.859\n",
      "batch 100\t-\tLoss: 0.6983\t-\tAccuracy: 0.828\n",
      "batch 200\t-\tLoss: 0.6656\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.6487\t-\tAccuracy: 0.906\n",
      "batch 400\t-\tLoss: 0.6948\t-\tAccuracy: 0.766\n",
      "batch 500\t-\tLoss: 0.6661\t-\tAccuracy: 0.797\n",
      "batch 600\t-\tLoss: 0.6337\t-\tAccuracy: 0.859\n",
      "batch 700\t-\tLoss: 0.6475\t-\tAccuracy: 0.828\n",
      "batch 800\t-\tLoss: 0.5873\t-\tAccuracy: 0.953\n",
      "batch 900\t-\tLoss: 0.6268\t-\tAccuracy: 0.859\n",
      "batch 1000\t-\tLoss: 0.6510\t-\tAccuracy: 0.781\n",
      "batch 1100\t-\tLoss: 0.6628\t-\tAccuracy: 0.797\n",
      "batch 1200\t-\tLoss: 0.6285\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.853\t-\tAUC ROC: 0.866\n",
      "================================================================================\n",
      "Epoch 7\n",
      "batch 0\t-\tLoss: 0.5798\t-\tAccuracy: 0.938\n",
      "batch 100\t-\tLoss: 0.5350\t-\tAccuracy: 0.953\n",
      "batch 200\t-\tLoss: 0.6628\t-\tAccuracy: 0.750\n",
      "batch 300\t-\tLoss: 0.5982\t-\tAccuracy: 0.844\n",
      "batch 400\t-\tLoss: 0.6852\t-\tAccuracy: 0.750\n",
      "batch 500\t-\tLoss: 0.5894\t-\tAccuracy: 0.875\n",
      "batch 600\t-\tLoss: 0.5979\t-\tAccuracy: 0.828\n",
      "batch 700\t-\tLoss: 0.6322\t-\tAccuracy: 0.844\n",
      "batch 800\t-\tLoss: 0.5318\t-\tAccuracy: 0.922\n",
      "batch 900\t-\tLoss: 0.5980\t-\tAccuracy: 0.859\n",
      "batch 1000\t-\tLoss: 0.5772\t-\tAccuracy: 0.859\n",
      "batch 1100\t-\tLoss: 0.5336\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5044\t-\tAccuracy: 0.906\n",
      "Test\t-\tAccuracy: 0.858\t-\tAUC ROC: 0.877\n",
      "================================================================================\n",
      "Epoch 8\n",
      "batch 0\t-\tLoss: 0.5621\t-\tAccuracy: 0.859\n",
      "batch 100\t-\tLoss: 0.5288\t-\tAccuracy: 0.875\n",
      "batch 200\t-\tLoss: 0.5359\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.5392\t-\tAccuracy: 0.844\n",
      "batch 400\t-\tLoss: 0.5955\t-\tAccuracy: 0.797\n",
      "batch 500\t-\tLoss: 0.6706\t-\tAccuracy: 0.734\n",
      "batch 600\t-\tLoss: 0.6389\t-\tAccuracy: 0.812\n",
      "batch 700\t-\tLoss: 0.5029\t-\tAccuracy: 0.875\n",
      "batch 800\t-\tLoss: 0.5800\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.5566\t-\tAccuracy: 0.844\n",
      "batch 1000\t-\tLoss: 0.5181\t-\tAccuracy: 0.906\n",
      "batch 1100\t-\tLoss: 0.5557\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.5466\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.862\t-\tAUC ROC: 0.872\n",
      "================================================================================\n",
      "Epoch 9\n",
      "batch 0\t-\tLoss: 0.5693\t-\tAccuracy: 0.828\n",
      "batch 100\t-\tLoss: 0.5772\t-\tAccuracy: 0.812\n",
      "batch 200\t-\tLoss: 0.5970\t-\tAccuracy: 0.797\n",
      "batch 300\t-\tLoss: 0.5528\t-\tAccuracy: 0.844\n",
      "batch 400\t-\tLoss: 0.5473\t-\tAccuracy: 0.844\n",
      "batch 500\t-\tLoss: 0.4875\t-\tAccuracy: 0.906\n",
      "batch 600\t-\tLoss: 0.6667\t-\tAccuracy: 0.734\n",
      "batch 700\t-\tLoss: 0.5982\t-\tAccuracy: 0.797\n",
      "batch 800\t-\tLoss: 0.4444\t-\tAccuracy: 0.922\n",
      "batch 900\t-\tLoss: 0.4689\t-\tAccuracy: 0.906\n",
      "batch 1000\t-\tLoss: 0.5394\t-\tAccuracy: 0.859\n",
      "batch 1100\t-\tLoss: 0.5802\t-\tAccuracy: 0.797\n",
      "batch 1200\t-\tLoss: 0.6829\t-\tAccuracy: 0.750\n",
      "Test\t-\tAccuracy: 0.861\t-\tAUC ROC: 0.867\n",
      "================================================================================\n",
      "Epoch 10\n",
      "batch 0\t-\tLoss: 0.4579\t-\tAccuracy: 0.875\n",
      "batch 100\t-\tLoss: 0.5050\t-\tAccuracy: 0.891\n",
      "batch 200\t-\tLoss: 0.5230\t-\tAccuracy: 0.891\n",
      "batch 300\t-\tLoss: 0.5312\t-\tAccuracy: 0.859\n",
      "batch 400\t-\tLoss: 0.5278\t-\tAccuracy: 0.906\n",
      "batch 500\t-\tLoss: 0.5524\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.4217\t-\tAccuracy: 0.938\n",
      "batch 700\t-\tLoss: 0.4853\t-\tAccuracy: 0.875\n",
      "batch 800\t-\tLoss: 0.5156\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.4763\t-\tAccuracy: 0.891\n",
      "batch 1000\t-\tLoss: 0.5772\t-\tAccuracy: 0.844\n",
      "batch 1100\t-\tLoss: 0.5750\t-\tAccuracy: 0.844\n",
      "batch 1200\t-\tLoss: 0.5978\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.861\t-\tAUC ROC: 0.876\n",
      "================================================================================\n",
      "Epoch 11\n",
      "batch 0\t-\tLoss: 0.4796\t-\tAccuracy: 0.906\n",
      "batch 100\t-\tLoss: 0.5597\t-\tAccuracy: 0.828\n",
      "batch 200\t-\tLoss: 0.4552\t-\tAccuracy: 0.906\n",
      "batch 300\t-\tLoss: 0.4989\t-\tAccuracy: 0.891\n",
      "batch 400\t-\tLoss: 0.5357\t-\tAccuracy: 0.859\n",
      "batch 500\t-\tLoss: 0.5770\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.4728\t-\tAccuracy: 0.922\n",
      "batch 700\t-\tLoss: 0.4678\t-\tAccuracy: 0.922\n",
      "batch 800\t-\tLoss: 0.5318\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.4425\t-\tAccuracy: 0.922\n",
      "batch 1000\t-\tLoss: 0.4903\t-\tAccuracy: 0.891\n",
      "batch 1100\t-\tLoss: 0.5416\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5626\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.880\n",
      "================================================================================\n",
      "Epoch 12\n",
      "batch 0\t-\tLoss: 0.5464\t-\tAccuracy: 0.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100\t-\tLoss: 0.5304\t-\tAccuracy: 0.844\n",
      "batch 200\t-\tLoss: 0.5147\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5171\t-\tAccuracy: 0.875\n",
      "batch 400\t-\tLoss: 0.5235\t-\tAccuracy: 0.859\n",
      "batch 500\t-\tLoss: 0.5743\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.5359\t-\tAccuracy: 0.875\n",
      "batch 700\t-\tLoss: 0.5029\t-\tAccuracy: 0.859\n",
      "batch 800\t-\tLoss: 0.4935\t-\tAccuracy: 0.875\n",
      "batch 900\t-\tLoss: 0.4518\t-\tAccuracy: 0.891\n",
      "batch 1000\t-\tLoss: 0.6458\t-\tAccuracy: 0.750\n",
      "batch 1100\t-\tLoss: 0.6086\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.5729\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.885\n",
      "================================================================================\n",
      "Epoch 13\n",
      "batch 0\t-\tLoss: 0.4872\t-\tAccuracy: 0.906\n",
      "batch 100\t-\tLoss: 0.5220\t-\tAccuracy: 0.891\n",
      "batch 200\t-\tLoss: 0.5231\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5083\t-\tAccuracy: 0.859\n",
      "batch 400\t-\tLoss: 0.4144\t-\tAccuracy: 0.953\n",
      "batch 500\t-\tLoss: 0.5300\t-\tAccuracy: 0.844\n",
      "batch 600\t-\tLoss: 0.5557\t-\tAccuracy: 0.812\n",
      "batch 700\t-\tLoss: 0.5601\t-\tAccuracy: 0.828\n",
      "batch 800\t-\tLoss: 0.5584\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.4495\t-\tAccuracy: 0.875\n",
      "batch 1000\t-\tLoss: 0.6618\t-\tAccuracy: 0.766\n",
      "batch 1100\t-\tLoss: 0.6582\t-\tAccuracy: 0.750\n",
      "batch 1200\t-\tLoss: 0.5228\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.886\n",
      "================================================================================\n",
      "Epoch 14\n",
      "batch 0\t-\tLoss: 0.4918\t-\tAccuracy: 0.891\n",
      "batch 100\t-\tLoss: 0.5958\t-\tAccuracy: 0.797\n",
      "batch 200\t-\tLoss: 0.6790\t-\tAccuracy: 0.750\n",
      "batch 300\t-\tLoss: 0.4247\t-\tAccuracy: 0.922\n",
      "batch 400\t-\tLoss: 0.6068\t-\tAccuracy: 0.828\n",
      "batch 500\t-\tLoss: 0.6205\t-\tAccuracy: 0.797\n",
      "batch 600\t-\tLoss: 0.5019\t-\tAccuracy: 0.891\n",
      "batch 700\t-\tLoss: 0.5268\t-\tAccuracy: 0.875\n",
      "batch 800\t-\tLoss: 0.5300\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.4457\t-\tAccuracy: 0.922\n",
      "batch 1000\t-\tLoss: 0.5752\t-\tAccuracy: 0.812\n",
      "batch 1100\t-\tLoss: 0.4905\t-\tAccuracy: 0.875\n",
      "batch 1200\t-\tLoss: 0.5376\t-\tAccuracy: 0.844\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.879\n",
      "================================================================================\n",
      "Epoch 15\n",
      "batch 0\t-\tLoss: 0.5846\t-\tAccuracy: 0.812\n",
      "batch 100\t-\tLoss: 0.5164\t-\tAccuracy: 0.891\n",
      "batch 200\t-\tLoss: 0.4944\t-\tAccuracy: 0.859\n",
      "batch 300\t-\tLoss: 0.5978\t-\tAccuracy: 0.812\n",
      "batch 400\t-\tLoss: 0.4517\t-\tAccuracy: 0.891\n",
      "batch 500\t-\tLoss: 0.5005\t-\tAccuracy: 0.859\n",
      "batch 600\t-\tLoss: 0.5242\t-\tAccuracy: 0.875\n",
      "batch 700\t-\tLoss: 0.6487\t-\tAccuracy: 0.766\n",
      "batch 800\t-\tLoss: 0.5524\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.6614\t-\tAccuracy: 0.766\n",
      "batch 1000\t-\tLoss: 0.4678\t-\tAccuracy: 0.875\n",
      "batch 1100\t-\tLoss: 0.5305\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5078\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.884\n",
      "================================================================================\n",
      "Epoch 16\n",
      "batch 0\t-\tLoss: 0.6388\t-\tAccuracy: 0.781\n",
      "batch 100\t-\tLoss: 0.4531\t-\tAccuracy: 0.891\n",
      "batch 200\t-\tLoss: 0.4918\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.5839\t-\tAccuracy: 0.844\n",
      "batch 400\t-\tLoss: 0.3915\t-\tAccuracy: 0.953\n",
      "batch 500\t-\tLoss: 0.6183\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.6386\t-\tAccuracy: 0.797\n",
      "batch 700\t-\tLoss: 0.4624\t-\tAccuracy: 0.906\n",
      "batch 800\t-\tLoss: 0.5554\t-\tAccuracy: 0.828\n",
      "batch 900\t-\tLoss: 0.5806\t-\tAccuracy: 0.859\n",
      "batch 1000\t-\tLoss: 0.5128\t-\tAccuracy: 0.859\n",
      "batch 1100\t-\tLoss: 0.6631\t-\tAccuracy: 0.781\n",
      "batch 1200\t-\tLoss: 0.5033\t-\tAccuracy: 0.875\n",
      "Test\t-\tAccuracy: 0.858\t-\tAUC ROC: 0.881\n",
      "================================================================================\n",
      "Epoch 17\n",
      "batch 0\t-\tLoss: 0.6080\t-\tAccuracy: 0.797\n",
      "batch 100\t-\tLoss: 0.5126\t-\tAccuracy: 0.859\n",
      "batch 200\t-\tLoss: 0.3975\t-\tAccuracy: 0.922\n",
      "batch 300\t-\tLoss: 0.4774\t-\tAccuracy: 0.891\n",
      "batch 400\t-\tLoss: 0.6470\t-\tAccuracy: 0.781\n",
      "batch 500\t-\tLoss: 0.5719\t-\tAccuracy: 0.828\n",
      "batch 600\t-\tLoss: 0.5347\t-\tAccuracy: 0.875\n",
      "batch 700\t-\tLoss: 0.3719\t-\tAccuracy: 0.969\n",
      "batch 800\t-\tLoss: 0.4206\t-\tAccuracy: 0.906\n",
      "batch 900\t-\tLoss: 0.5035\t-\tAccuracy: 0.875\n",
      "batch 1000\t-\tLoss: 0.5419\t-\tAccuracy: 0.859\n",
      "batch 1100\t-\tLoss: 0.4793\t-\tAccuracy: 0.906\n",
      "batch 1200\t-\tLoss: 0.4251\t-\tAccuracy: 0.922\n",
      "Test\t-\tAccuracy: 0.862\t-\tAUC ROC: 0.884\n",
      "================================================================================\n",
      "Epoch 18\n",
      "batch 0\t-\tLoss: 0.5110\t-\tAccuracy: 0.875\n",
      "batch 100\t-\tLoss: 0.4757\t-\tAccuracy: 0.875\n",
      "batch 200\t-\tLoss: 0.5932\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.5739\t-\tAccuracy: 0.828\n",
      "batch 400\t-\tLoss: 0.6276\t-\tAccuracy: 0.812\n",
      "batch 500\t-\tLoss: 0.5819\t-\tAccuracy: 0.812\n",
      "batch 600\t-\tLoss: 0.4884\t-\tAccuracy: 0.844\n",
      "batch 700\t-\tLoss: 0.5293\t-\tAccuracy: 0.844\n",
      "batch 800\t-\tLoss: 0.6034\t-\tAccuracy: 0.812\n",
      "batch 900\t-\tLoss: 0.5812\t-\tAccuracy: 0.828\n",
      "batch 1000\t-\tLoss: 0.4794\t-\tAccuracy: 0.891\n",
      "batch 1100\t-\tLoss: 0.5319\t-\tAccuracy: 0.859\n",
      "batch 1200\t-\tLoss: 0.5180\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.883\n",
      "================================================================================\n",
      "Epoch 19\n",
      "batch 0\t-\tLoss: 0.5627\t-\tAccuracy: 0.828\n",
      "batch 100\t-\tLoss: 0.4651\t-\tAccuracy: 0.891\n",
      "batch 200\t-\tLoss: 0.4979\t-\tAccuracy: 0.875\n",
      "batch 300\t-\tLoss: 0.5710\t-\tAccuracy: 0.844\n",
      "batch 400\t-\tLoss: 0.4564\t-\tAccuracy: 0.891\n",
      "batch 500\t-\tLoss: 0.4597\t-\tAccuracy: 0.875\n",
      "batch 600\t-\tLoss: 0.5149\t-\tAccuracy: 0.875\n",
      "batch 700\t-\tLoss: 0.4435\t-\tAccuracy: 0.906\n",
      "batch 800\t-\tLoss: 0.4384\t-\tAccuracy: 0.906\n",
      "batch 900\t-\tLoss: 0.5892\t-\tAccuracy: 0.812\n",
      "batch 1000\t-\tLoss: 0.4812\t-\tAccuracy: 0.875\n",
      "batch 1100\t-\tLoss: 0.5678\t-\tAccuracy: 0.812\n",
      "batch 1200\t-\tLoss: 0.4807\t-\tAccuracy: 0.859\n",
      "Test\t-\tAccuracy: 0.863\t-\tAUC ROC: 0.884\n",
      "================================================================================\n",
      "Epoch 20\n",
      "batch 0\t-\tLoss: 0.4503\t-\tAccuracy: 0.875\n",
      "batch 100\t-\tLoss: 0.4863\t-\tAccuracy: 0.875\n",
      "batch 200\t-\tLoss: 0.5692\t-\tAccuracy: 0.812\n",
      "batch 300\t-\tLoss: 0.6049\t-\tAccuracy: 0.781\n",
      "batch 400\t-\tLoss: 0.5113\t-\tAccuracy: 0.875\n",
      "batch 500\t-\tLoss: 0.4914\t-\tAccuracy: 0.875\n",
      "batch 600\t-\tLoss: 0.4235\t-\tAccuracy: 0.922\n",
      "batch 700\t-\tLoss: 0.6122\t-\tAccuracy: 0.797\n",
      "batch 800\t-\tLoss: 0.5016\t-\tAccuracy: 0.859\n",
      "batch 900\t-\tLoss: 0.5550\t-\tAccuracy: 0.812\n",
      "batch 1000\t-\tLoss: 0.4463\t-\tAccuracy: 0.891\n",
      "batch 1100\t-\tLoss: 0.4442\t-\tAccuracy: 0.891\n",
      "batch 1200\t-\tLoss: 0.6094\t-\tAccuracy: 0.828\n",
      "Test\t-\tAccuracy: 0.860\t-\tAUC ROC: 0.883\n",
      "================================================================================\n",
      "Epoch 21\n",
      "batch 0\t-\tLoss: 0.5483\t-\tAccuracy: 0.844\n",
      "batch 100\t-\tLoss: 0.6177\t-\tAccuracy: 0.781\n",
      "batch 200\t-\tLoss: 0.6065\t-\tAccuracy: 0.797\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-4b8618772a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_test_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, data_loader, verbose)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2909\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    print('Epoch {:d}'.format(epoch))\n",
    "    tree.train_epoch(train_loader)\n",
    "    tree.print_test_metrics(test_loader)\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('root.path_prob', Parameter containing:\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "  [torch.cuda.FloatTensor of size 64x1 (GPU 0)]),\n",
       " ('root.fc.weight', Parameter containing:\n",
       "  -9.6712e-05  1.1778e-04 -2.0696e+00 -1.1940e+00\n",
       "  [torch.cuda.FloatTensor of size 1x4 (GPU 0)]),\n",
       " ('root.fc.bias', Parameter containing:\n",
       "  1.00000e-04 *\n",
       "   -1.3078\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.fc.weight', Parameter containing:\n",
       "  -0.0000  0.0000 -0.1419  0.0000\n",
       "  [torch.cuda.FloatTensor of size 1x4 (GPU 0)]),\n",
       " ('root.left_child.fc.bias', Parameter containing:\n",
       "  1.00000e-05 *\n",
       "    6.1891\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.left_child.fc.weight', Parameter containing:\n",
       "  1.00000e-05 *\n",
       "    0.8253  0.6095  3.8504  0.1220\n",
       "  [torch.cuda.FloatTensor of size 1x4 (GPU 0)]),\n",
       " ('root.left_child.left_child.fc.bias', Parameter containing:\n",
       "  1.00000e-06 *\n",
       "    2.4894\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.left_child.left_child.classes_ratio', Parameter containing:\n",
       "   0.3300\n",
       "  -1.4125\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('root.left_child.left_child.right_child.classes_ratio', Parameter containing:\n",
       "   0.1457\n",
       "  -1.5969\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('root.left_child.right_child.fc.weight', Parameter containing:\n",
       "  1.00000e-05 *\n",
       "    0.8580 -3.4358  0.7044  3.0088\n",
       "  [torch.cuda.FloatTensor of size 1x4 (GPU 0)]),\n",
       " ('root.left_child.right_child.fc.bias', Parameter containing:\n",
       "  1.00000e-06 *\n",
       "    1.1477\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.left_child.right_child.left_child.classes_ratio', Parameter containing:\n",
       "   0.5693\n",
       "  -0.8347\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('root.left_child.right_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   1.8007\n",
       "   0.3967\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('root.right_child.fc.weight', Parameter containing:\n",
       "  -0.0000 -0.0000 -0.3853  0.0001\n",
       "  [torch.cuda.FloatTensor of size 1x4 (GPU 0)]),\n",
       " ('root.right_child.fc.bias', Parameter containing:\n",
       "  1.00000e-02 *\n",
       "   -3.6643\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.left_child.fc.weight', Parameter containing:\n",
       "  -3.4228e-05 -3.3920e-06 -5.3806e-01 -3.1154e-01\n",
       "  [torch.cuda.FloatTensor of size 1x4 (GPU 0)]),\n",
       " ('root.right_child.left_child.fc.bias', Parameter containing:\n",
       "  1.00000e-05 *\n",
       "    1.5739\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.left_child.left_child.classes_ratio', Parameter containing:\n",
       "   0.1207\n",
       "   0.5398\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('root.right_child.left_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -0.8209\n",
       "   0.6340\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('root.right_child.right_child.fc.weight', Parameter containing:\n",
       "   0.0000 -0.0000  0.9609  0.2319\n",
       "  [torch.cuda.FloatTensor of size 1x4 (GPU 0)]),\n",
       " ('root.right_child.right_child.fc.bias', Parameter containing:\n",
       "  1.00000e-05 *\n",
       "    8.6120\n",
       "  [torch.cuda.FloatTensor of size 1 (GPU 0)]),\n",
       " ('root.right_child.right_child.left_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "  -2.1316\n",
       "   0.1990\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('root.right_child.right_child.right_child.classes_ratio',\n",
       "  Parameter containing:\n",
       "   0.6567\n",
       "   1.2153\n",
       "  [torch.cuda.FloatTensor of size 2 (GPU 0)]),\n",
       " ('bn.weight', Parameter containing:\n",
       "   0.3870\n",
       "   0.4204\n",
       "  -3.8382\n",
       "   2.3326\n",
       "  [torch.cuda.FloatTensor of size 4 (GPU 0)]),\n",
       " ('bn.bias', Parameter containing:\n",
       "   0.2104\n",
       "  -0.1448\n",
       "   0.0008\n",
       "  -0.1986\n",
       "  [torch.cuda.FloatTensor of size 4 (GPU 0)])]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tree.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949999514031\n",
      "0.950978878039\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=4)\n",
    "dtc.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_train, dtc.predict_proba(X_train)[:, 1]))\n",
    "print(roc_auc_score(y_test, dtc.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_classes=10, n_informative=150, n_features=28*28, )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "train_loader = DataLoader(dataset=ExampleData(X_train, y_train),\n",
    "                          batch_size=64,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=ExampleData(X_test, y_test),\n",
    "                         batch_size=64,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = Arguments(max_depth=8, cuda=True, input_dim=28*28, output_dim=10, lmbda=0.1, lr=0.1, momentum=0,\n",
    "                 log_interval=100, epochs=200, l1_const=0.001\n",
    "                )\n",
    "\n",
    "tree = newmodel.SoftDecisionTree(args)\n",
    "tree.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\t-\tLoss: 2.6031\t-\tAccuracy: 0.144\n",
      "batch 100\t-\tLoss: 2.5936\t-\tAccuracy: 0.156\n",
      "Test\t-\tAccuracy: 0.172\n",
      "================================================================================\n",
      "Epoch 1\n",
      "batch 0\t-\tLoss: 2.5844\t-\tAccuracy: 0.188\n",
      "batch 100\t-\tLoss: 2.5872\t-\tAccuracy: 0.172\n",
      "Test\t-\tAccuracy: 0.175\n",
      "================================================================================\n",
      "Epoch 2\n",
      "batch 0\t-\tLoss: 2.5713\t-\tAccuracy: 0.194\n",
      "batch 100\t-\tLoss: 2.5904\t-\tAccuracy: 0.172\n",
      "Test\t-\tAccuracy: 0.177\n",
      "================================================================================\n",
      "Epoch 3\n",
      "batch 0\t-\tLoss: 2.5582\t-\tAccuracy: 0.212\n",
      "batch 100\t-\tLoss: 2.5729\t-\tAccuracy: 0.194\n",
      "Test\t-\tAccuracy: 0.180\n",
      "================================================================================\n",
      "Epoch 4\n",
      "batch 0\t-\tLoss: 2.5915\t-\tAccuracy: 0.176\n",
      "batch 100\t-\tLoss: 2.5988\t-\tAccuracy: 0.170\n",
      "Test\t-\tAccuracy: 0.182\n",
      "================================================================================\n",
      "Epoch 5\n",
      "batch 0\t-\tLoss: 2.5868\t-\tAccuracy: 0.188\n",
      "batch 100\t-\tLoss: 2.5575\t-\tAccuracy: 0.208\n",
      "Test\t-\tAccuracy: 0.185\n",
      "================================================================================\n",
      "Epoch 6\n",
      "batch 0\t-\tLoss: 2.5649\t-\tAccuracy: 0.206\n",
      "batch 100\t-\tLoss: 2.5536\t-\tAccuracy: 0.208\n",
      "Test\t-\tAccuracy: 0.189\n",
      "================================================================================\n",
      "Epoch 7\n",
      "batch 0\t-\tLoss: 2.5553\t-\tAccuracy: 0.218\n",
      "batch 100\t-\tLoss: 2.5407\t-\tAccuracy: 0.204\n",
      "Test\t-\tAccuracy: 0.192\n",
      "================================================================================\n",
      "Epoch 8\n",
      "batch 0\t-\tLoss: 2.5637\t-\tAccuracy: 0.198\n",
      "batch 100\t-\tLoss: 2.5416\t-\tAccuracy: 0.186\n",
      "Test\t-\tAccuracy: 0.196\n",
      "================================================================================\n",
      "Epoch 9\n",
      "batch 0\t-\tLoss: 2.5834\t-\tAccuracy: 0.188\n",
      "batch 100\t-\tLoss: 2.5508\t-\tAccuracy: 0.192\n",
      "Test\t-\tAccuracy: 0.200\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=ExampleData(X_train, y_train),\n",
    "                          batch_size=500,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=ExampleData(X_test, y_test),\n",
    "                         batch_size=500,\n",
    "                         shuffle=False)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('Epoch {:d}'.format(epoch))\n",
    "    tree.train_epoch(train_loader)\n",
    "    tree.print_test_metrics(test_loader)\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\t-\tLoss: 2.5424\t-\tAccuracy: 0.156\n",
      "batch 100\t-\tLoss: 2.5474\t-\tAccuracy: 0.219\n",
      "batch 200\t-\tLoss: 2.5901\t-\tAccuracy: 0.156\n",
      "batch 300\t-\tLoss: 2.5701\t-\tAccuracy: 0.172\n",
      "batch 400\t-\tLoss: 2.4701\t-\tAccuracy: 0.359\n",
      "batch 500\t-\tLoss: 2.5265\t-\tAccuracy: 0.234\n",
      "batch 600\t-\tLoss: 2.6003\t-\tAccuracy: 0.172\n",
      "batch 700\t-\tLoss: 2.5260\t-\tAccuracy: 0.203\n",
      "batch 800\t-\tLoss: 2.5243\t-\tAccuracy: 0.266\n",
      "batch 900\t-\tLoss: 2.5092\t-\tAccuracy: 0.266\n",
      "batch 1000\t-\tLoss: 2.5306\t-\tAccuracy: 0.188\n",
      "batch 1100\t-\tLoss: 2.5620\t-\tAccuracy: 0.172\n",
      "batch 1200\t-\tLoss: 2.5321\t-\tAccuracy: 0.219\n",
      "Test\t-\tAccuracy: 0.227\n",
      "================================================================================\n",
      "Epoch 1\n",
      "batch 0\t-\tLoss: 2.4917\t-\tAccuracy: 0.266\n",
      "batch 100\t-\tLoss: 2.4879\t-\tAccuracy: 0.250\n",
      "batch 200\t-\tLoss: 2.5350\t-\tAccuracy: 0.219\n",
      "batch 300\t-\tLoss: 2.4958\t-\tAccuracy: 0.172\n",
      "batch 400\t-\tLoss: 2.4879\t-\tAccuracy: 0.266\n",
      "batch 500\t-\tLoss: 2.5383\t-\tAccuracy: 0.281\n",
      "batch 600\t-\tLoss: 2.5790\t-\tAccuracy: 0.156\n",
      "batch 700\t-\tLoss: 2.5474\t-\tAccuracy: 0.156\n",
      "batch 800\t-\tLoss: 2.5311\t-\tAccuracy: 0.203\n",
      "batch 900\t-\tLoss: 2.5202\t-\tAccuracy: 0.250\n",
      "batch 1000\t-\tLoss: 2.4703\t-\tAccuracy: 0.203\n",
      "batch 1100\t-\tLoss: 2.4637\t-\tAccuracy: 0.203\n",
      "batch 1200\t-\tLoss: 2.4116\t-\tAccuracy: 0.297\n",
      "Test\t-\tAccuracy: 0.249\n",
      "================================================================================\n",
      "Epoch 2\n",
      "batch 0\t-\tLoss: 2.5046\t-\tAccuracy: 0.266\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-aa7af9b46093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_test_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, data_loader, verbose)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0my_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             loss = (\n\u001b[1;32m    210\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_primary_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpaths_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistribs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mpaths_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bs x numleaves x 1,  bs x numleaves x c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mget_probs\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m         of all the leaves in the soft tree\"\"\"\n\u001b[1;32m    133\u001b[0m         \u001b[0mvisit_root_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mleaves_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisit_root_prob\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [(bs x 1, bs x c), ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mleaves_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mleaves_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [(bs x 1, bs x 1, ...), (bs x c, bs x c, ...)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mpaths_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaves_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bs x numleaves x 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mget_probs\u001b[0;34m(self, x, path_prob)\u001b[0m\n\u001b[1;32m     80\u001b[0m         subtree_leaves_probs.extend(self\n\u001b[1;32m     81\u001b[0m                                     \u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left_child'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                     \u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_prob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo_right_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                                     )\n\u001b[1;32m     84\u001b[0m         subtree_leaves_probs.extend(self\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mget_probs\u001b[0;34m(self, x, path_prob)\u001b[0m\n\u001b[1;32m     84\u001b[0m         subtree_leaves_probs.extend(self\n\u001b[1;32m     85\u001b[0m                                     \u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right_child'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                     \u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_prob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo_right_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                                     )\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msubtree_leaves_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mget_probs\u001b[0;34m(self, x, path_prob)\u001b[0m\n\u001b[1;32m     84\u001b[0m         subtree_leaves_probs.extend(self\n\u001b[1;32m     85\u001b[0m                                     \u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right_child'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                     \u001b[0;34m.\u001b[0m\u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_prob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo_right_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                                     )\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msubtree_leaves_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mget_probs\u001b[0;34m(self, x, path_prob)\u001b[0m\n\u001b[1;32m     76\u001b[0m         of all the leaves in the respective subtree\"\"\"\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo_right_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0msubtree_leaves_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         subtree_leaves_probs.extend(self\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_matrix_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=ExampleData(X_train, y_train),\n",
    "                          batch_size=64,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=ExampleData(X_test, y_test),\n",
    "                         batch_size=64,\n",
    "                         shuffle=False)\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print('Epoch {:d}'.format(epoch))\n",
    "    tree.train_epoch(train_loader)\n",
    "    tree.print_test_metrics(test_loader)\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py:149: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert ((x is not None) != (paths_probs is not None and distribs is not None),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "batch 0\t-\tLoss: 2.9574\t-\tAccuracy: 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100\t-\tLoss: 2.9582\t-\tAccuracy: 0.062\n",
      "batch 200\t-\tLoss: 2.9531\t-\tAccuracy: 0.094\n",
      "batch 300\t-\tLoss: 2.9295\t-\tAccuracy: 0.141\n",
      "batch 400\t-\tLoss: 2.9090\t-\tAccuracy: 0.094\n",
      "batch 500\t-\tLoss: 2.9020\t-\tAccuracy: 0.172\n",
      "batch 600\t-\tLoss: 2.8853\t-\tAccuracy: 0.047\n",
      "batch 700\t-\tLoss: 2.8881\t-\tAccuracy: 0.141\n",
      "batch 800\t-\tLoss: 2.8598\t-\tAccuracy: 0.141\n",
      "batch 900\t-\tLoss: 2.8545\t-\tAccuracy: 0.109\n",
      "batch 1000\t-\tLoss: 2.8441\t-\tAccuracy: 0.219\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-fb4c2c5bfeba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {:d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_test_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wind/Projects/playground/PytorchSoftTree/newmodel.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, data_loader, verbose)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=ExampleData(X_train, y_train),\n",
    "                          batch_size=64,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=ExampleData(X_test, y_test),\n",
    "                         batch_size=64,\n",
    "                         shuffle=False)\n",
    "\n",
    "args = Arguments(max_depth=8, cuda=True, input_dim=28*28, output_dim=10, lmbda=0.1, lr=0.01, momentum=0.5,\n",
    "                 log_interval=100, epochs=200, l1_const=0.001\n",
    "                )\n",
    "\n",
    "tree = newmodel.SoftDecisionTree(args)\n",
    "tree.cuda();\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print('Epoch {:d}'.format(epoch))\n",
    "    tree.train_epoch(train_loader)\n",
    "    tree.print_test_metrics(test_loader)\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 3\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[1, 2], \n",
    "              [3, 4]]).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
